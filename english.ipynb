{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "amnt = 20000\n",
    "cols = ['sentence', 'is_english']\n",
    "df = pd.read_csv(\"train_data\", header=None, nrows=amnt, names=cols, dtype=pd.StringDtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import ascii_lowercase\n",
    "def create_vec(sentence: str) -> pd.DataFrame:\n",
    "    letters_dict = {c:np.char.count(sentence, c) for c in ascii_lowercase}\n",
    "    doubles = sum(np.char.count(sentence, c + c) for c in ascii_lowercase)\n",
    "    words = [word for word in sentence.split(' ') if word != '']\n",
    "    word_lengths =list(map(len, words)) \n",
    "    average_word_length = np.average(word_lengths)\n",
    "    longest_word_length = max(word_lengths)\n",
    "    shortest_word_length = min(word_lengths)\n",
    "    \n",
    "    \n",
    "    return [len(sentence)] + [letters_dict[c] for c in ascii_lowercase] + [doubles, average_word_length, longest_word_length, shortest_word_length] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = df['sentence'].apply(create_vec)\n",
    "is_english = df['is_english']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       len   a  b  c  d   e   f  g  h   i  ...  u  v  w  x  y  z doubles  \\\n",
      "0       88   3  2  4  5   6   1  5  1   2  ...  2  0  2  1  2  3       1   \n",
      "1      113   8  0  3  3  12   2  1  8   5  ...  2  0  3  0  2  1       4   \n",
      "2       94   5  3  1  6  10   1  1  6   5  ...  3  2  0  0  3  1       7   \n",
      "3      164   7  2  7  5   9   2  2  8  17  ...  6  0  2  0  1  0       4   \n",
      "4      136   3  7  0  7   7   8  5  4   2  ...  5  6  5  8  4  4       3   \n",
      "...    ...  .. .. .. ..  ..  .. .. ..  ..  ... .. .. .. .. .. ..     ...   \n",
      "19995   93   9  1  1  3  14   0  2  3   6  ...  2  3  2  0  0  0       1   \n",
      "19996  108  11  2  2  0  10   2  2  4   9  ...  1  0  3  0  1  1       2   \n",
      "19997   90   3  0  1  4  14   3  2  6   5  ...  1  0  0  0  0  0       2   \n",
      "19998  154   9  6  3  4   7  10  9  7   5  ...  7  4  5  9  2  4       8   \n",
      "19999  177  15  6  3  4  12   1  1  8  13  ...  6  1  4  0  4  0       3   \n",
      "\n",
      "      average_word_len longest_word_len shortes_word_len  \n",
      "0            13.833333               33                1  \n",
      "1             4.944444               13                1  \n",
      "2             9.333333               47                1  \n",
      "3             4.689655               12                1  \n",
      "4            16.125000               41                1  \n",
      "...                ...              ...              ...  \n",
      "19995         5.714286               12                2  \n",
      "19996         5.411765               12                1  \n",
      "19997         4.055556                9                1  \n",
      "19998        24.833333               67                2  \n",
      "19999         5.357143               13                2  \n",
      "\n",
      "[20000 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "params_df = pd.DataFrame((item for item in params), columns=['len'] + [c for c in ascii_lowercase] + ['doubles', 'average_word_len', 'longest_word_len', 'shortest_word_len'])\n",
    "print(params_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       len   a  b  c  d   e   f  g  h   i  ...  v  w  x  y  z doubles  \\\n",
      "0       88   3  2  4  5   6   1  5  1   2  ...  0  2  1  2  3       1   \n",
      "1      113   8  0  3  3  12   2  1  8   5  ...  0  3  0  2  1       4   \n",
      "2       94   5  3  1  6  10   1  1  6   5  ...  2  0  0  3  1       7   \n",
      "3      164   7  2  7  5   9   2  2  8  17  ...  0  2  0  1  0       4   \n",
      "4      136   3  7  0  7   7   8  5  4   2  ...  6  5  8  4  4       3   \n",
      "...    ...  .. .. .. ..  ..  .. .. ..  ..  ... .. .. .. .. ..     ...   \n",
      "19995   93   9  1  1  3  14   0  2  3   6  ...  3  2  0  0  0       1   \n",
      "19996  108  11  2  2  0  10   2  2  4   9  ...  0  3  0  1  1       2   \n",
      "19997   90   3  0  1  4  14   3  2  6   5  ...  0  0  0  0  0       2   \n",
      "19998  154   9  6  3  4   7  10  9  7   5  ...  4  5  9  2  4       8   \n",
      "19999  177  15  6  3  4  12   1  1  8  13  ...  1  4  0  4  0       3   \n",
      "\n",
      "      average_word_len longest_word_len shortes_word_len is_english  \n",
      "0            13.833333               33                1      False  \n",
      "1             4.944444               13                1      False  \n",
      "2             9.333333               47                1      False  \n",
      "3             4.689655               12                1      False  \n",
      "4            16.125000               41                1      False  \n",
      "...                ...              ...              ...        ...  \n",
      "19995         5.714286               12                2       True  \n",
      "19996         5.411765               12                1      False  \n",
      "19997         4.055556                9                1      False  \n",
      "19998        24.833333               67                2      False  \n",
      "19999         5.357143               13                2       True  \n",
      "\n",
      "[20000 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nums = pd.concat([params_df, is_english], axis=1)\n",
    "print(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/projects/arazim/english/venv/lib/python3.9/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7978"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train,  y_test = train_test_split(params_df, is_english, random_state=53)\n",
    "model = make_pipeline(preprocessing.StandardScaler(), knn())\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test.values, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/projects/arazim/english/venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/mnt/d/projects/arazim/english/venv/lib/python3.9/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8238"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train,  y_test = train_test_split(params_df, is_english, random_state=53)\n",
    "model = make_pipeline(preprocessing.StandardScaler(), LogisticRegression())\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test.values, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8258"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train,  y_test = train_test_split(params_df, is_english, random_state=53)\n",
    "model = make_pipeline(preprocessing.StandardScaler(), svm.SVC())\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8256"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "X_train, X_test, y_train,  y_test = train_test_split(params_df, is_english, random_state=53)\n",
    "model = RidgeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence      string[python]\n",
      "is_english    string[python]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
